# MLOps Mini Pipeline

A reproducible, containerised batch pipeline that computes rolling-mean trading signals on cryptocurrency OHLCV data and emits structured JSON metrics.

---

## Folder Structure

```
mlops-task/
├── run.py            # Main pipeline script
├── config.yaml       # Pipeline configuration
├── data.csv          # Input OHLCV dataset (10 000 rows)
├── requirements.txt  # Python dependencies
├── Dockerfile        # Container definition
├── metrics.json      # Example output (generated by a successful run)
├── run.log           # Example log file (generated by a successful run)
└── README.md         # This file
```

---

## Dependencies

| Package  | Version | Purpose               |
|----------|---------|-----------------------|
| pandas   | 2.1.4   | Data loading & rolling mean |
| numpy    | 1.26.4  | Random seed & numeric ops   |
| pyyaml   | 6.0.1   | YAML config parsing         |

---

## Setup Instructions

```bash
# Install dependencies
pip install -r requirements.txt
```

---

## Local Execution

```bash
python run.py \
  --input    data.csv \
  --config   config.yaml \
  --output   metrics.json \
  --log-file run.log
```

---

## Docker Instructions

```bash
# Build the Docker image
docker build -t mlops-task .

# Run the container
docker run --rm mlops-task
```

The container automatically runs the pipeline on startup, prints metrics to stdout, and exits with code `0` on success or `1` on failure.

---

## Expected Output

**`metrics.json`**
```json
{
  "version": "v1",
  "rows_processed": 10000,
  "metric": "signal_rate",
  "value": 0.4989,
  "latency_ms": 24,
  "seed": 42,
  "status": "success"
}
```

**`run.log`**
```
2024-01-06 16:00:00 - INFO - Job started
2024-01-06 16:00:00 - INFO - Config loaded: seed=42, window=5, version=v1
2024-01-06 16:00:00 - INFO - Data loaded: 10000 rows
2024-01-06 16:00:00 - INFO - Rolling mean calculated with window=5
2024-01-06 16:00:00 - INFO - Signals generated
2024-01-06 16:00:00 - INFO - Metrics: signal_rate=0.4989, rows_processed=10000
2024-01-06 16:00:00 - INFO - Job completed successfully in 24ms
```

**On error**, `metrics.json` will contain:
```json
{
  "version": "v1",
  "status": "error",
  "error_message": "Description of what went wrong"
}
```

---

## Configuration (`config.yaml`)

| Key     | Type   | Description                        |
|---------|--------|------------------------------------|
| seed    | int    | NumPy random seed for reproducibility |
| window  | int    | Rolling mean window size           |
| version | string | Pipeline version label             |

---

## Pipeline Logic

1. **Load config** — parse `config.yaml`, set `numpy` random seed.
2. **Load data** — read CSV, validate required `close` column.
3. **Rolling mean** — `close.rolling(window=5).mean()` (NaN for first 4 rows).
4. **Signal generation** — `1` if `close > rolling_mean`, else `0` (NaN rows → `0`).
5. **Metrics** — compute `signal_rate` (mean of signals), write `metrics.json`.
6. **Logging** — every step logged to `run.log` and stdout with timestamps.
